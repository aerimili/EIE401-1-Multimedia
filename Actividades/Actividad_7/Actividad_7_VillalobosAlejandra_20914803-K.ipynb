{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerimili/EIE401-1-Multimedia/blob/main/Actividades/Actividad_7/Actividad_7_VillalobosAlejandra_20914803-K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a",
      "metadata": {
        "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a"
      },
      "source": [
        "<h1><center>\n",
        "\n",
        "</center></h1>\n",
        "<font size=\"6\"><center>\n",
        "EIE 401\n",
        "PROCESAMIENTO DIGITAL MULTIMEDIA\n",
        "</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c",
      "metadata": {
        "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c"
      },
      "source": [
        "\n",
        "<center><h2>Actividad 7</h2></center>\n",
        "<center><h3>Image</h3></center>\n",
        "<center><h3>Profesor: Jorge Cardenas</h3></center>\n",
        "\n",
        "<center><h3>Por: Alejandra Villalobos</h3></center>\n",
        "<center><h5>Pontificia Universidad Catolica de Valparaiso</h5></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d",
      "metadata": {
        "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d"
      },
      "source": [
        "## 1. Operaciones usando Pytorch y OpenCV\n",
        "\n",
        "### 1.1 Instala Numpy, Pytorch y OpenCV:\n",
        "- Carga una imagen desde un archivo con extensión JPG, usando numpy, pytorch y opencv.\n",
        "- Presenta la imagen\n",
        "- Transforma la imagen de color a escala de grises usando cada uno de los paquetes\n",
        "- Guarda la imagen nueva.\n",
        "- Presenta la imagen transformada en el notebook.\n",
        "\n",
        "<p align=\"justify\">\n",
        "Asegurate de presentar adecuandamente la imagen, usando Matplotlib u otro medio de ploteo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "id": "d0ab6ee5-d7a3-4cf7-9aee-1d1a76b5525f",
      "metadata": {
        "tags": [],
        "id": "d0ab6ee5-d7a3-4cf7-9aee-1d1a76b5525f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#Subir archivo Tokio.jpg en Colab\n",
        "print(\"Suba Tokyo.jpg: \")\n",
        "uploadedjpg = files.upload()\n",
        "\n",
        "#Subir archivo image.png en Colab\n",
        "print(\"Suba image.png: \")\n",
        "uploadedpng = files.upload()"
      ],
      "metadata": {
        "id": "Wjhw5895eXsH",
        "collapsed": true
      },
      "id": "Wjhw5895eXsH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rutajpg = \"Tokyo.jpg\" #Ruta donde se encuentra imagen jpg"
      ],
      "metadata": {
        "id": "6XwyrFspiVlM"
      },
      "id": "6XwyrFspiVlM",
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Numpy"
      ],
      "metadata": {
        "id": "DrtEQ93IiWq1"
      },
      "id": "DrtEQ93IiWq1"
    },
    {
      "cell_type": "code",
      "source": [
        "imagenPil = Image.open(rutajpg) #Cargar imagen jpg original"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y6ZH_1qXiHh2"
      },
      "id": "y6ZH_1qXiHh2",
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen original\n",
        "plt.imshow(imagenPil)\n",
        "plt.title(\"Imagen jpg con Numpy\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "WDExEePGnwRj"
      },
      "id": "WDExEePGnwRj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenNpGris = imagenPil.convert(\"L\") #Transformar imagen a escala de grises"
      ],
      "metadata": {
        "id": "qHr2oWK4nxx-"
      },
      "id": "qHr2oWK4nxx-",
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guardarNumpy = imagenNpGris.save(\"imagenNpGris.jpg\") #Guardar imagen nueva\n",
        "\n",
        "imagenNpGrisSave = Image.open(\"imagenNpGris.jpg\") #Cargar imagen nueva"
      ],
      "metadata": {
        "id": "E3KudG5WpA-l"
      },
      "id": "E3KudG5WpA-l",
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen en escala de grises\n",
        "plt.imshow(imagenNpGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Numpy en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Aeo65AXlqMJ2"
      },
      "id": "Aeo65AXlqMJ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen jpg original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPil)\n",
        "plt.title(\"Imagen jpg con Numpy\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenNpGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Numpy en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "biiBiC3fqpZJ"
      },
      "id": "biiBiC3fqpZJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Torch"
      ],
      "metadata": {
        "id": "7EDKTEdrsE3d"
      },
      "id": "7EDKTEdrsE3d"
    },
    {
      "cell_type": "code",
      "source": [
        "imagenTorch = transforms.ToTensor()(imagenPil) #Tranformar imagen a tensor"
      ],
      "metadata": {
        "id": "WMrGGNbDtw1S"
      },
      "id": "WMrGGNbDtw1S",
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen original trabajada con Torch\n",
        "plt.imshow(imagenTorch.permute(1,2,0))\n",
        "plt.title(\"Imagen jpg con Torch\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "bI_Ord7fsH6z"
      },
      "id": "bI_Ord7fsH6z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenTorchGris = transforms.Grayscale()(imagenTorch) #Transformar imagen torch a escala de grises"
      ],
      "metadata": {
        "id": "l9yRNnCpuSBq"
      },
      "id": "l9yRNnCpuSBq",
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenTorchGrisPil = transforms.ToPILImage()(imagenTorchGris) #Tranformar tensor gris a imagen PIL\n",
        "\n",
        "guardarTorch = imagenTorchGrisPil.save(\"imagenTorchGris.jpg\") #Guardar imagen nueva\n",
        "\n",
        "imagenTorchGrisSave = Image.open(\"imagenTorchGris.jpg\") #Cargar imagen nueva"
      ],
      "metadata": {
        "id": "v9syTwrVu0jl"
      },
      "id": "v9syTwrVu0jl",
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen en escala de grises trabajada con Torch\n",
        "plt.imshow(imagenTorchGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Torch en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "lp8eCHOSvL5Z"
      },
      "id": "lp8eCHOSvL5Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen jpg original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenTorch.permute(1,2,0))\n",
        "plt.title(\"Imagen jpg con Torch\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenTorchGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Torch en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "-s6zwraewlSg"
      },
      "id": "-s6zwraewlSg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####OPENCV"
      ],
      "metadata": {
        "id": "VIlyonK-iCTC"
      },
      "id": "VIlyonK-iCTC"
    },
    {
      "cell_type": "code",
      "source": [
        "imagenCv = cv2.imread(rutajpg) #Cargar imagen original con OpenCv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wKlMpjSqfeva"
      },
      "id": "wKlMpjSqfeva",
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen original trabajada con OpenCv\n",
        "plt.imshow(imagenCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B758iVMUxCso"
      },
      "id": "B758iVMUxCso",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenAGriscv = cv2.cvtColor(imagenCv, cv2.COLOR_BGR2GRAY) #Transformar imagen a escala de grises\n",
        "\n",
        "guardarImagen = cv2.imwrite(\"Tokyogriscv.jpg\", imagenAGriscv) #Guardar imagen nueva\n",
        "\n",
        "imagenGrisCv = cv2.imread(\"Tokyogriscv.jpg\") #Cargar imagen en escala de grises con OpenCv"
      ],
      "metadata": {
        "id": "cc6Eflm8xAcX"
      },
      "id": "cc6Eflm8xAcX",
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen en escala de grises trabajada con OpenCv\n",
        "plt.imshow(imagenGrisCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7TRgjL7uzwJp"
      },
      "id": "7TRgjL7uzwJp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen jpg original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenGrisCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "EOzwZ8VtqFbk"
      },
      "id": "EOzwZ8VtqFbk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28db8b8d",
      "metadata": {
        "id": "28db8b8d"
      },
      "source": [
        "## 2. Multiples operaciones con tensores\n",
        "### ¡USA LA IMAGEN ADJUNTA image.png!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rutapng = \"image.png\" #Ruta donde se encuentra imagen png\n",
        "imagenPng = cv2.imread(rutapng) #Cargar imagen png original\n",
        "imagenGrisPng = cv2.cvtColor(imagenPng, cv2.COLOR_BGR2GRAY) #Transformar imagen png a escala de grises"
      ],
      "metadata": {
        "id": "Gr885TdatjRr"
      },
      "id": "Gr885TdatjRr",
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenGrisPng, cmap = \"gray\")\n",
        "plt.title(\"Imagen png en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xjSEF0Q90sFD"
      },
      "id": "xjSEF0Q90sFD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b0f7428a",
      "metadata": {
        "id": "b0f7428a"
      },
      "source": [
        "#### 2.1 Aplica una transformación puntual. Modifica el valor de los pixeles considerando un valor de umbral (threshold). la función de treshold debe ser una rampa con una pendiente dada (tu defines el valor de la pendiente) y cuyo valor mínimo será 0 y el máximo será 255 (valores típicos de los pixeles)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 128 #Valor de umbral\n",
        "slope = 2 #Valor de pendiente\n",
        "\n",
        "def thre(pixel, thres, slope):\n",
        "  \"\"\"\n",
        "  Calcula la transformación puntual de una imagen.\n",
        "\n",
        "  Parámetros:\n",
        "\n",
        "  pixel: Pixel de la imagen a transformar.\n",
        "  thres: Umbral.\n",
        "  slope: Pendiente.\n",
        "  \"\"\"\n",
        "  #Si el pixel es menor al umbral, aplica la transformación con la pendiente\n",
        "  if pixel<thres:\n",
        "    return max(0,pixel*slope)\n",
        "  #Si el pixel es mayor o igual al umbral, aplica la transformación con la pendiente\n",
        "  else:\n",
        "    return min(255,pixel*slope)\n",
        "\n",
        "imgTransf = np.zeros_like(imagenPng) #Nos aseguramos que el valor minimo sea 0 y el máximo 255\n",
        "\n",
        "#Iteración sobre cada pixel de la imagen\n",
        "for i in range(imagenPng.shape[0]):\n",
        "  for j in range(imagenPng.shape[1]):\n",
        "    for c in range(imagenPng.shape[2]):\n",
        "      imgTransf[i,j,c] = thre(imagenPng[i,j,c], threshold, slope) #Aplica la transformación a cada canal."
      ],
      "metadata": {
        "id": "KDvA43azeKPF"
      },
      "id": "KDvA43azeKPF",
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y con transformación puntual\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgTransf[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png con transformación puntual\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5inGthHxgaGc"
      },
      "id": "5inGthHxgaGc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede apreciar que la transformación cambia la intensidad dependiendo si los pixeles están por debajo o encima del umbral."
      ],
      "metadata": {
        "id": "Dh68fZH4tGt3"
      },
      "id": "Dh68fZH4tGt3"
    },
    {
      "cell_type": "markdown",
      "id": "c203b1f0",
      "metadata": {
        "id": "c203b1f0"
      },
      "source": [
        "#### 2.2 Aplica una transformación en la vecindad.\n",
        "- Debes hacer una vecindad con dimensiones de 5x5 pixeles.\n",
        "- Aplica la transformación de tal forma que los pixeles cambien para tener el valor correspondiente al máximo de todos los vecinos.\n",
        "- Debes hacer la misma operación a lo largo y ancho de toda la imagen. Esto implica, de forma iterativa, recorrer la imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vecindad(imagen, Tvecindad):\n",
        "  \"\"\"\n",
        "  Calcula la transformación en la vecindad de una imagen.\n",
        "\n",
        "  Parámetros:\n",
        "\n",
        "  imagen: Imagen a transformar.\n",
        "  Tvecindad: Tamaño de la vecindad.\n",
        "  \"\"\"\n",
        "  imgVec = np.zeros_like(imagen) #Nos aseguramos que el valor minimo sea 0 y el máximo 255\n",
        "\n",
        "  #Iteración sobre la imagen con desplazamiento de tamaño de vecindad\n",
        "  for i in range(imagen.shape[0] - Tvecindad + 1):\n",
        "    for j in range(imagen.shape[1] - Tvecindad + 1):\n",
        "\n",
        "      vecindad = imagen[i:i+Tvecindad, j:j+Tvecindad] #vecindad de imagen en posición actual\n",
        "      maxVec = np.max(vecindad, axis=(0,1)) #Valor máximo de la vecindad\n",
        "      imgVec[i:i+Tvecindad, j:j+Tvecindad] = maxVec #Se asigna el valor máximo a toda la vecindad\n",
        "\n",
        "  return imgVec\n",
        "\n",
        "Tvecindad = 5 #Tamaño de la vecindad de 5x5\n",
        "imagenVecindad = vecindad(imagenPng, Tvecindad) #Se crea imagen con transformación en la vecindad"
      ],
      "metadata": {
        "id": "KT034PdiEBG-"
      },
      "id": "KT034PdiEBG-",
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y con transformación en la vecindad\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenVecindad[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png con transformación en la vecindad\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Gao-UOAxGMC9"
      },
      "id": "Gao-UOAxGMC9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La transformación en la vecindad afecta a cada pixel, reemplazandolo por una vecindad cuadrada de tamaño elegido, esto provoca un efecto de \"imagen pixeleada\", perdiendo resolución."
      ],
      "metadata": {
        "id": "iXFEHQobu8kA"
      },
      "id": "iXFEHQobu8kA"
    },
    {
      "cell_type": "markdown",
      "id": "5bf09ac2",
      "metadata": {
        "id": "5bf09ac2"
      },
      "source": [
        "#### 2.3 Aplica transformación de intensidad\n",
        "- Debes hacer una vecindad con dimensiones de 10x10 pixeles.\n",
        "- Aplica la transformación que aparece en la ecuación de tal forma que los pixeles cambien dependiendo de la posición (r) y el coeficiente c (de tu elección).\n",
        "- Debes hacer la misma operación a lo largo y ancho de toda la imagen. ESto implica, de forma iterativa, recorrer la imagen."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tvecindad2 = 10 #Tamaño de vecindad de 10x10\n",
        "c = 20 #Valor coeficiente c\n",
        "\n",
        "def intensidad(c, r):\n",
        "  \"\"\"\n",
        "  Calcula la transformación de intensidad.\n",
        "\n",
        "  Parámetros:\n",
        "\n",
        "  c: Coeficiente \"c\".\n",
        "  r: Posición.\n",
        "  \"\"\"\n",
        "  return c*np.log(1+r)\n",
        "\n",
        "def transIntensidad(imagen, Tvecindad, c):\n",
        "  \"\"\"\n",
        "  Calcula la transformación de intensidad en la vecindad de una imagen.\n",
        "\n",
        "  Parámetros:\n",
        "\n",
        "  imagen: Imagen a transformar\n",
        "  Tvecindad: Tamaño de la vecindad.\n",
        "  c: Coeficiente \"c\"\n",
        "  \"\"\"\n",
        "  imgVec = np.zeros_like(imagen) #Nos aseguramos que el valor minimo sea 0 y el máximo 255\n",
        "\n",
        "  #Iteración sobre la imagen con desplazamiento de tamaño de vecindad\n",
        "  for i in range(imagen.shape[0] - Tvecindad + 1):\n",
        "    for j in range(imagen.shape[1] - Tvecindad + 1):\n",
        "      vecindad = imagen[i:i+Tvecindad, j:j+Tvecindad] #Vecindad de imagen en posición actual\n",
        "\n",
        "      transVec = intensidad(c,vecindad) #Transformación de intensidad en la vecindad\n",
        "      transVec = np.clip(transVec, 0, 255) #Nos aseguramos que el valor minimo sea 0 y el máximo 255\n",
        "      imgVec[i:i+Tvecindad, j:j+Tvecindad] = transVec #Asignamos transformación de intensidad a vecindad\n",
        "\n",
        "  return imgVec\n",
        "\n",
        "imagenVecindad2 = transIntensidad(imagenPng, Tvecindad2, c) #Se crea imagen con transformación de intensidad"
      ],
      "metadata": {
        "id": "jhW6KGetjpfD"
      },
      "id": "jhW6KGetjpfD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y con transformación de intensidad\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenVecindad2[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png con transformación de intensidad\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YPnhO2Z3KpZa"
      },
      "id": "YPnhO2Z3KpZa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la figura que se obtiene, se puede ver que se modifica la intensidad de los pixeles de la imagen, cambiando el brillo y contraste de la imagen final."
      ],
      "metadata": {
        "id": "y0eeeLT8x_UI"
      },
      "id": "y0eeeLT8x_UI"
    },
    {
      "cell_type": "markdown",
      "id": "d9230405",
      "metadata": {
        "id": "d9230405"
      },
      "source": [
        "#### 2.4 Operación con Kernel\n",
        "- Realiza tres operaciones de convolución en cascada.\n",
        "- Utiliza torch nn.Conv2d\n",
        "- Debes calcular el stride, padding y demás parámetros para que obtengas 16 canales de salida.\n",
        "- Muestra una imagen de cada canal resultante de la convolución."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "id": "f8bb041e",
      "metadata": {
        "id": "f8bb041e"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagenPngTorch = transforms.ToTensor()(imagenPng) #Tranformar imagen a tensor\n",
        "imagenPngTorch = imagenPngTorch.unsqueeze(0) #Agregar canal de batch"
      ],
      "metadata": {
        "id": "ywyMViTwSKwG"
      },
      "id": "ywyMViTwSKwG",
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = 3 #Valor de kernel\n",
        "stride = 1 #Valor de stride\n",
        "padding = 1 #Valor de padding\n",
        "\n",
        "conv1 = nn.Conv2d(3, 8, kernel, stride, padding) #1era capa de convolución, entran 3 canales y salen 8.\n",
        "conv2 = nn.Conv2d(8, 8, kernel, stride, padding) #2da capa de convolución, entran 8 canales y salen 8.\n",
        "conv3 = nn.Conv2d(8, 16, kernel, stride, padding) #3era capa de convolución, entran 8 canales y salen 16.\n",
        "\n",
        "#Convolución en cascada\n",
        "im1 = conv1(imagenPngTorch)\n",
        "im2 = conv2(im1)\n",
        "im3 = conv3(im2)"
      ],
      "metadata": {
        "id": "1xckCUXtQqNm"
      },
      "id": "1xckCUXtQqNm",
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar cada canal\n",
        "fig, axes = plt.subplots(4,4,figsize=(12, 12))\n",
        "for i in range(16):\n",
        "  fila = i//4\n",
        "  columna = i%4\n",
        "  axes[fila, columna].imshow(im3[0, i].detach().numpy(), cmap=\"gray\")\n",
        "  axes[fila, columna].set_title(f\"Canal {i+1}\")\n",
        "  axes[fila, columna].axis(\"off\")"
      ],
      "metadata": {
        "id": "fCP2D38SzYn3"
      },
      "id": "fCP2D38SzYn3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede ver que, según las imágenes resultantes, cada canal \"resalta\" partes diferentes de la imagen"
      ],
      "metadata": {
        "id": "BYY2fL_JzhC-"
      },
      "id": "BYY2fL_JzhC-"
    },
    {
      "cell_type": "markdown",
      "id": "eb8294e2",
      "metadata": {
        "id": "eb8294e2"
      },
      "source": [
        "## 3. Realiza la inversión de imagen\n",
        "\n",
        "### 3.1 Utilizando estrictamente numpy, busca y usa una imagen binaria y realizar la inversión de dicha imagen.\n",
        "### Recuerda adjuntar la imagen a la entrega de tu trabajo.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#Subir imagen binaria en Colab\n",
        "print(\"Suba archivo binaria.png: \")\n",
        "uploaded3 = files.upload()"
      ],
      "metadata": {
        "id": "FpyJTKK_zYuE"
      },
      "id": "FpyJTKK_zYuE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "3cf800d9",
      "metadata": {
        "id": "3cf800d9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "ruta3 = \"binaria.png\" #Ruta donde se encuentra imagen binaria\n",
        "\n",
        "imagen3 = Image.open(ruta3) #Cargar imagen binaria\n",
        "imagen3Np = np.array(imagen3) #Convertir imagen a un array de numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M = imagen3Np.shape[0] #Primer canal de la imagen\n",
        "N = imagen3Np.shape[1] #Segundo canal de la imagen\n",
        "\n",
        "imgInvertidaNp = np.zeros_like(imagen3Np) #Nos aseguramos que el valor minimo sea 0 y el máximo 255\n",
        "\n",
        "#Inversión de la imagen\n",
        "for i in range(M):\n",
        "  for j in range(N):\n",
        "      #Si un pixel de la imagen es 255 se cambia a 0\n",
        "      if imagen3Np[i, j] == 255:\n",
        "        imgInvertidaNp[i, j] = 0\n",
        "      #Si un pixel de la imagen es 0 se cambia a 255\n",
        "      else:\n",
        "        imgInvertidaNp[i, j] = 255"
      ],
      "metadata": {
        "id": "PaQZ4gTqlhNl"
      },
      "id": "PaQZ4gTqlhNl",
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen binaria original e invertida con numpy\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagen3Np, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria original con Numpy\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgInvertidaNp, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria invertida con Numpy\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "P3o5AtCFAjBB"
      },
      "id": "P3o5AtCFAjBB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2c2d43d8",
      "metadata": {
        "id": "2c2d43d8"
      },
      "source": [
        "### 3.1 Usando Pytorch y opencv, realiza la inversión de la misma imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Torch"
      ],
      "metadata": {
        "id": "UTteuWfB58TM"
      },
      "id": "UTteuWfB58TM"
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "id": "fdf35251",
      "metadata": {
        "id": "fdf35251"
      },
      "outputs": [],
      "source": [
        "imagen3Torch = transforms.ToTensor()(imagen3).squeeze() #Convertir imagen a tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M = imagen3Torch.shape[0] #Primer canal de la imagen\n",
        "N = imagen3Torch.shape[1] #Segundo canal de la imagen\n",
        "\n",
        "imgInvertidaTorch = torch.where(imagen3Torch == 1, torch.tensor(0), torch.tensor(1)) #Inversión de imagen"
      ],
      "metadata": {
        "id": "IrmcDtM0B8Kl"
      },
      "id": "IrmcDtM0B8Kl",
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen binaria riginal e invertida con Torch\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagen3Torch, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria original con Torch\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgInvertidaTorch, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria invertida con Torch\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "59Hh4JKqA_Gd"
      },
      "id": "59Hh4JKqA_Gd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####OpenCv"
      ],
      "metadata": {
        "id": "DUIJpZli5_Fo"
      },
      "id": "DUIJpZli5_Fo"
    },
    {
      "cell_type": "code",
      "source": [
        "imagen3Cv = cv2.imread(ruta3) #Cargar imagen binaria con OpenCv\n",
        "\n",
        "imgInvertidaCv = cv2.bitwise_not(imagen3Cv) #Inversión de imagen con OpenCv"
      ],
      "metadata": {
        "id": "Ne5o2q806Bd4"
      },
      "id": "Ne5o2q806Bd4",
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen binaria original e invertida con OpenCv\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagen3Cv, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria original con OpenCv\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgInvertidaCv, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria invertida con OpenCv\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Coiql6xD6aNe"
      },
      "id": "Coiql6xD6aNe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c64b67c8",
      "metadata": {
        "id": "c64b67c8"
      },
      "source": [
        "## 4. Segmentación de imagen\n",
        "#### 4.1 Realiza un algoritmo para dividir una imagen con 3 canales RGB de 512x512, en parches (secciones) de 16x16. Presenta cada parche generado de la imagen.\n",
        "El algoritmo debe tolerar el cambio de imagen por una de menor tamano (128, 64). Claramente, en cada caso el número de parches será menor.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eceb0add",
      "metadata": {
        "id": "eceb0add",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def parches(imagen, Tparche):\n",
        "  \"\"\"\n",
        "  Divide una imagen en secciones (parches) y muestra cada sección.\n",
        "\n",
        "  Parámetros:\n",
        "\n",
        "  imagen: Imagen a dividir.\n",
        "  Tparche: Tamaño de la sección.\n",
        "  \"\"\"\n",
        "  parches = [] #Definir lista vacía para almacenar los parches\n",
        "\n",
        "  #Iteración sobre ña imagen con un paso de tamaño del parche\n",
        "  for i in range(0, imagen.shape[0], Tparche):\n",
        "    for j in range(0, imagen.shape[1], Tparche):\n",
        "      parche = imagen[i:i + Tparche, j:j + Tparche] #Extraer parche de Tparche x Tparche\n",
        "      parches.append(parche)\n",
        "\n",
        "  #Columnas y filas para mostrar los parches\n",
        "  nColumnas = int(np.ceil(np.sqrt(len(parches))))\n",
        "  nFilas = int(np.ceil(len(parches) / nColumnas))\n",
        "\n",
        "  fig, axes = plt.subplots(nFilas, nColumnas, figsize = (nColumnas, nFilas))\n",
        "\n",
        "  #Mostrar todos los parches\n",
        "  for i, parche in enumerate(parches):\n",
        "    ax = axes.flatten()[i]\n",
        "    ax.imshow(cv2.cvtColor(parche, cv2.COLOR_BGR2RGB))\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "  for ax in axes.flatten()[len(parches):]:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "\n",
        "Tparche = 16 #Tamaño de parches de 16x16\n",
        "\n",
        "parches = parches(imagenPng, Tparche) #División de imagen en secciones"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0",
      "metadata": {
        "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0"
      },
      "source": [
        "## 5. Referencias\n",
        "<p align=\"justify\">\n",
        "    \n",
        "[OpenCV] https://docs.opencv.org/4.x/d7/da8/tutorial_table_of_content_imgproc.html\n",
        "\n",
        "[inversion] https://medium.com/analytics-vidhya/inverting-an-image-using-numpys-broadcasting-method-1f5beb7f9fa5#:~:text=In%20order%20to%20invert%20the,negation)%20operation%20to%20the%20image.\n",
        "\n",
        "[Image.open] https://www.geeksforgeeks.org/python-pil-image-open-method/\n",
        "\n",
        "[Image module] https://pillow.readthedocs.io/en/stable/reference/Image.html\n",
        "\n",
        "[Conversión a escala de grises]https://www.delftstack.com/es/howto/python/convert-image-to-grayscale-python/\n",
        "\n",
        "[torchvision.transforms] https://pytorch.org/vision/0.9/transforms.html\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}