{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerimili/EIE401-1-Multimedia/blob/main/Actividades/Actividad_5/Actividad_5_VillalobosAlejandra_20914803_K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a",
      "metadata": {
        "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a"
      },
      "source": [
        "<h1><center>\n",
        "\n",
        "</center></h1>\n",
        "<font size=\"6\"><center>\n",
        "EIE 401\n",
        "PROCESAMIENTO DIGITAL MULTIMEDIA\n",
        "</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c",
      "metadata": {
        "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c"
      },
      "source": [
        "\n",
        "<center><h2>Actividad 5</h2></center>\n",
        "<center><h3>Audio</h3></center>\n",
        "<center><h3>Profesor: Jorge Cardenas</h3></center>\n",
        "\n",
        "<center><h3>Por: Alejandra Villalobos</h3></center>\n",
        "<center><h5>Pontificia Universidad Catolica de Valparaiso</h5></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d",
      "metadata": {
        "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d"
      },
      "source": [
        "## 1. Aplique la transformada rápida de fourier a una señal de audio\n",
        "<p align=\"justify\">\n",
        "El archivo de audio debe ser formato .WAV, con menos de 30 segundo de duración.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from scipy import signal\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "khwt98EKjebX"
      },
      "id": "khwt98EKjebX",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#Subir archivo de audio\n",
        "print(\"Cargue archivo de audio: \")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ISAxzfyZTvs6"
      },
      "id": "ISAxzfyZTvs6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = \"Exercise2.7_adultmale_b_d2.wav\" #Definición de ruta del audio\n",
        "\n",
        "fs, datos = wavfile.read(ruta) #Leer archivo de audio y extraer la frecuencia de muestreo y el audio\n",
        "datos = datos.astype(np.float32)  #Converción de audio a valores float32\n",
        "\n",
        "t = len(datos) / fs #Definición de duración de audio\n",
        "tiempo = np.linspace(0, t, len(datos)) #Definición de vector tiempo"
      ],
      "metadata": {
        "id": "sFG8R0IGSK_K"
      },
      "id": "sFG8R0IGSK_K",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfica de señal de audio original\n",
        "plt.figure(figsize = (20,6))\n",
        "plt.plot(tiempo, datos)\n",
        "plt.title(\"Señal de audio\")\n",
        "plt.xlabel(\"Tiempo(s)\")\n",
        "plt.ylabel(\"Amplitud\")"
      ],
      "metadata": {
        "id": "FwkVv_bc_v5R"
      },
      "id": "FwkVv_bc_v5R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformada = np.fft.fft(datos) #Aplicación de transformada de Fourier de señal de audio\n",
        "frecuencias = np.fft.fftfreq(len(datos), 1/fs) #Calculo de componentes frecuenciales"
      ],
      "metadata": {
        "id": "0pfUGM-WT5Ji"
      },
      "id": "0pfUGM-WT5Ji",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfica de espectro de frecuencia de la señal\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.plot(np.abs(frecuencias), np.abs(transformada))\n",
        "plt.title(\"Espectro de frecuencia de señal de audio.\")\n",
        "plt.xlabel(\"Frecuencia(Hz)\")\n",
        "plt.ylabel(\"Magnitud\")"
      ],
      "metadata": {
        "id": "JmoD4PawUTZa"
      },
      "id": "JmoD4PawUTZa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(datos, rate = fs) #Reproducción de señal de audio original"
      ],
      "metadata": {
        "id": "Rui2eUpwVbuZ"
      },
      "id": "Rui2eUpwVbuZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28db8b8d",
      "metadata": {
        "id": "28db8b8d"
      },
      "source": [
        "## 2. Obtén el espectrograma de tu señal de audio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa #Instalación de librería librosa"
      ],
      "metadata": {
        "id": "ifkpT4fUaZ8Q"
      },
      "id": "ifkpT4fUaZ8Q",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "X = librosa.stft(datos) #Transformada de Fourier de tiempo corto de señal\n",
        "\n",
        "xdb = librosa.amplitude_to_db(abs(X)) #Conversión de transformada a decibeles"
      ],
      "metadata": {
        "id": "vQSv7ldvaeBY"
      },
      "id": "vQSv7ldvaeBY",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualización del espectrograma\n",
        "librosa.display.specshow(xdb, sr = fs, x_axis = \"time\", y_axis=\"log\")\n",
        "plt.title(\"Espectrograma de señal de audio\")\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "FEDp1e_Qw8QP"
      },
      "id": "FEDp1e_Qw8QP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El espectrograma muestra cómo varía la energía de la señal de audio en función del tiempo y la frecuencia. Cada palabra pronunciada en el audio se representa como una banda vertical con mayor energía en frecuencias más bajas. A frecuencias más altas se puede ver una disminución gradual de la energía."
      ],
      "metadata": {
        "id": "-IcrKqCcxNm0"
      },
      "id": "-IcrKqCcxNm0"
    },
    {
      "cell_type": "markdown",
      "id": "eb8294e2",
      "metadata": {
        "id": "eb8294e2"
      },
      "source": [
        "## 3. Slicing\n",
        "Desarrolla un framento de código que te permita tomar una señal de audio y framentarla en N segmentos o slices. Debe asignar la longitud temporal de cada slice y el programa debe indicar el número de slices que quedan. Considera que al final puede quedar un slice de longitud diferente a todos los demas.\n",
        "\n",
        "En el slicing debes también incluir un gap o overlap a lado y lado de cada uno de los fragmentos. Este overlap debe ser ajustable del número de muestras que constituyen dicho overlap.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def slicing(datos, tiempoSlice, overlap):\n",
        "  \"\"\"\n",
        "  Realizar fragmentación de señal de audio con overlap.\n",
        "\n",
        "  Parámetros:\n",
        "  datos: Señal de audio\n",
        "  tiempo_slice: Longitud temporal de cada slice\n",
        "  overlap: Solapamiento entre cada fragmento\n",
        "  \"\"\"\n",
        "\n",
        "  nMuestras = len(datos) #Definición de número de muestras de señal de audio\n",
        "  tiempoTotal = nMuestras/fs #Tiempo total de la señal de audio\n",
        "  nSlices = int(tiempoTotal/tiempoSlice) #Número de slices redondeado\n",
        "  nSlicesReal = tiempoTotal / tiempoSlice #Número de slices sin redondeo\n",
        "  slices = [] #Lista vacía para almacenar los slices generados\n",
        "  muestrasSlice = int(tiempoSlice * fs) #Número de muestras de cada slice\n",
        "  muestrasOverlap = int(overlap * fs) #Número de muestras de overlap\n",
        "\n",
        "  #Generación de slices con overlap\n",
        "  for i in range(nSlices):\n",
        "    inicio = int(i * (tiempoSlice * fs - overlap))\n",
        "    fin = inicio + muestrasSlice\n",
        "    slices.append(datos[inicio:fin])\n",
        "\n",
        "  print(f\"Se generaron {nSlices} slices.\") #Imprimir en pantalla el número de slices que se generaron\n",
        "\n",
        "  print(f\"Cada slice dura {tiempoSlice} segundos.\") #Imprime en pantalla la longitud temporal de cada slice\n",
        "\n",
        "  #Si hay un último slice de diferente tamaño, calcula e imprime en pantalla que existe y su duración\n",
        "  if fin < nMuestras:\n",
        "    ultimoInicio = nMuestras - muestrasSlice\n",
        "    ultimoSlice = datos[ultimoInicio:]\n",
        "    slices.append(ultimoSlice)\n",
        "    print(\"Se genero un ultimo slice con longitud diferente.\")\n",
        "\n",
        "    tiempoUltimoSlice = (nSlicesReal - nSlices) * tiempoSlice\n",
        "    print(f\"El ultimo slice dura {round(tiempoUltimoSlice, 3)} segundos.\")\n",
        "\n",
        "  return slices\n",
        "\n",
        "#Definir parámetros de la función\n",
        "tiempoSlice = 0.5 #Longitud temporal de cada slice\n",
        "overlap = 1600 #Número de muestras de overlap\n",
        "\n",
        "audioSlicing = slicing(datos, tiempoSlice, overlap) #Llama a la función para generar slices\n"
      ],
      "metadata": {
        "id": "SMMCuiJYYfVx"
      },
      "id": "SMMCuiJYYfVx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2c2d43d8",
      "metadata": {
        "id": "2c2d43d8"
      },
      "source": [
        "## 3.1 Slicing usando Pytorch de la señal obtenida en el primer punto.\n",
        "Debes crear un array con los slices creados a partir de tensores en pytorch.\n",
        "Grafica un par de tus slices y reproduce el audio.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "datosTensor = torch.tensor(datos) #Convertir valores de la señal de audio en tensor\n",
        "\n",
        "def slicing_torch(datosTorch, tiempoSliceTorch, overlapTorch):\n",
        "  \"\"\"\n",
        "  Realizar fragmentación de señal de audio con overlap usando pytorch.\n",
        "\n",
        "  Parámetros:\n",
        "  datos_torch: Señal de audio en tensor\n",
        "  tiempo_slice: Longitud temporal de cada slice\n",
        "  overlap: Solapamiento entre cada fragmento\n",
        "  \"\"\"\n",
        "\n",
        "  nMuestrasTorch = len(datosTorch) #Definición de número de muestras de señal de audio\n",
        "  tiempoTotalTorch = nMuestrasTorch/fs #Tiempo total de la señal de audio\n",
        "  nSlicesTorch = int(tiempoTotalTorch/tiempoSliceTorch) #Número de slices redondeado\n",
        "  nSlicesRealTorch = tiempoTotalTorch / tiempoSliceTorch #Número de slices sin redondeo\n",
        "  slicesTorch = [] #Lista vacía para almacenar los slices generados\n",
        "  muestrasSliceTorch = int(tiempoSliceTorch * fs) #Número de muestras de cada slice\n",
        "  muestrasOverlapTorch = overlapTorch * fs #Número de muestras de overlap\n",
        "\n",
        "  #Generación de slices con overlap\n",
        "  for i in range(nSlicesTorch):\n",
        "    inicioTorch = int(i * (tiempoSliceTorch *fs - overlapTorch))\n",
        "    finTorch = inicioTorch + muestrasSliceTorch\n",
        "    slicesTorch.append(datos[inicioTorch:finTorch])\n",
        "\n",
        "  print(f\"Se generaron {nSlicesTorch} slices.\") #Imprimir en pantalla el número de slices que se generaron\n",
        "\n",
        "  print(f\"Cada slice dura {tiempoSliceTorch} segundos.\") #Imprime en pantalla la longitud temporal de cada slice\n",
        "\n",
        "  #Si hay un último slice de diferente tamaño, calcula e imprime en pantalla que existe y su duración\n",
        "  if finTorch < nMuestrasTorch:\n",
        "    ultimoInicioTorch = nMuestrasTorch - muestrasSliceTorch\n",
        "    ultimoSliceTorch = datos[ultimoInicioTorch:]\n",
        "    slicesTorch.append(torch.tensor(ultimoSliceTorch))\n",
        "    print(\"Se genero un ultimo slice con longitud diferente.\")\n",
        "\n",
        "    tiempoUltimoSliceTorch = (nSlicesRealTorch - nSlicesTorch) * tiempoSliceTorch\n",
        "    print(f\"El ultimo slice dura {round(tiempoUltimoSliceTorch, 3)} segundos.\")\n",
        "\n",
        "  return slicesTorch\n",
        "\n",
        "#Definir parámetros de la función\n",
        "tiempoSliceTorch = 2 #Longitud temporal de cada slice\n",
        "overlapTorch = 20000 #Número de muestras de overlap\n",
        "\n",
        "audioSlicingTorch = slicing_torch(datosTensor, tiempoSliceTorch, overlapTorch) #Llama a la función para generar slices"
      ],
      "metadata": {
        "id": "Yg5-56bsqdqL"
      },
      "id": "Yg5-56bsqdqL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = torch.arange(0, len(audioSlicingTorch[0])) / fs #Vector de tiempo del primer slice\n",
        "time2 = torch.arange(len(audioSlicingTorch[0]) - int(overlapTorch), len(audioSlicingTorch[0]) + len(audioSlicingTorch[1]) - int(overlapTorch)) / fs #Vectorde tiempo de 2do slice\n",
        "\n",
        "#Gráfica de primer y segundo slice de la señal de audio\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(time, audioSlicingTorch[0])\n",
        "plt.title('Primer slice')\n",
        "plt.xlabel(\"Tiempo(s)\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(time2, audioSlicingTorch[1])\n",
        "plt.title('Segundo slice')\n",
        "plt.xlabel(\"Tiempo(s)\")\n",
        "plt.ylabel(\"Amplitud\")"
      ],
      "metadata": {
        "id": "4BvG2b2EvbXP"
      },
      "id": "4BvG2b2EvbXP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(audioSlicingTorch[0], rate = fs) #Reproducción de primer slice"
      ],
      "metadata": {
        "id": "tJLh9_nNvnRP"
      },
      "id": "tJLh9_nNvnRP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(audioSlicingTorch[1], rate = fs) #Reproducción de segundo slice"
      ],
      "metadata": {
        "id": "oNZEPBEtxXny"
      },
      "id": "oNZEPBEtxXny",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c64b67c8",
      "metadata": {
        "id": "c64b67c8"
      },
      "source": [
        "## 4. Filtro Butterworth para una señal de audio.\n",
        "Diseña y aplica un filtro butterworth a tu señal de audio.\n",
        "Muestra un gráfico con la respuesta del filtro butterworth y explica el resultado."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ordenes = [8, 6, 4, 2] #Lista de ordenes a comparar\n",
        "\n",
        "datosFiltrado = [] #Lista vacía para almacenar datos de señal filtrada\n",
        "\n",
        "for orden in ordenes:\n",
        "\n",
        "  b, a = signal.butter(orden, 1000, fs = fs, btype = \"low\") #Diseño de filtro Butterworth\n",
        "\n",
        "  w, h = signal.freqz(b, a, fs=fs) #Cálculo de respuesta en frecuencia del filtro\n",
        "  plt.plot(w, 20*np.log10(abs(h)), label = f\"Orden {orden}\") #Gráfica de respuesta en frecuencia de señal filtrada\n",
        "\n",
        "  dataFiltrada = signal.lfilter(b, a, datos) #Filtrar la señal\n",
        "  datosFiltrado.append(dataFiltrada)  #Agregar datos filtrados a la lista\n",
        "\n",
        "#Agregar características de gráfico\n",
        "plt.title('Respuesta de los filtros Butterworth en distintos oredenes')\n",
        "plt.xlabel('Frecuencia [Hz]')\n",
        "plt.ylabel('Ganancia [dB]')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "prAX0EEovCmD"
      },
      "id": "prAX0EEovCmD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La ganancia negativa en el gráfico indica que el filtro está atenuando la señal, especialmente para eliminar el ruido y conservar únicamente la información relevante. Se observa que a medida que aumenta el orden del filtro, la caída de la ganancia se vuelve más pronunciada, lo que se traduce en una pendiente más empinada en la respuesta del filtro. Cada curva en el gráfico representa cómo el filtro atenúa gradualmente las frecuencias por encima de la frecuencia de corte."
      ],
      "metadata": {
        "id": "1bgFlwUVsZXe"
      },
      "id": "1bgFlwUVsZXe"
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfica de señal de audio original v/s señal de audio filtrada\n",
        "plt.figure(figsize = (20,6))\n",
        "plt.plot(tiempo, datos, label = \"Señal original\")\n",
        "plt.plot(tiempo, datosFiltrado[3], label = \"Señal filtrada\")\n",
        "plt.title(\"Comparacion de audio original y audio filtrado con orden 2\")\n",
        "plt.xlabel(\"Tiempo(s)\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "lns6SzYCacuZ"
      },
      "id": "lns6SzYCacuZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(datosFiltrado[3], rate = fs) #Reproducción de señal de audio filtrada"
      ],
      "metadata": {
        "id": "BLarERtfclYU"
      },
      "id": "BLarERtfclYU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0",
      "metadata": {
        "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0"
      },
      "source": [
        "## 4. Referencias\n",
        "<p align=\"justify\">\n",
        "    \n",
        "[Análisis espectral para audio] https://ccrma.stanford.edu/~jos/mdft/mdft-python.html\n",
        "\n",
        "[Análisis espectral] https://currents.soest.hawaii.edu/ocn_data_analysis/_static/Spectrum.html\n",
        "\n",
        "[FFT en audio] https://realpython.com/python-scipy-fft/#time-domain-vs-frequency-domain\n",
        "\n",
        "[Filtro] https://pythonguia.com/filtro-de-python-scipy-butterworth/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}