{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerimili/EIE401-1-Multimedia/blob/main/Actividades/Actividad_6/Actividad_6_VillalobosAlejandra_20914803_K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a",
      "metadata": {
        "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a"
      },
      "source": [
        "<h1><center>\n",
        "\n",
        "</center></h1>\n",
        "<font size=\"6\"><center>\n",
        "EIE 401\n",
        "PROCESAMIENTO DIGITAL MULTIMEDIA\n",
        "</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c",
      "metadata": {
        "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c"
      },
      "source": [
        "\n",
        "<center><h2>Actividad 6</h2></center>\n",
        "<center><h3>Audio</h3></center>\n",
        "<center><h3>Profesor: Jorge Cardenas</h3></center>\n",
        "\n",
        "<center><h3>Por: Alejandra Villalobos</h3></center>\n",
        "<center><h5>Pontificia Universidad Catolica de Valparaiso</h5></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d",
      "metadata": {
        "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d"
      },
      "source": [
        "## 1. Operaciones para extracción de características.\n",
        "\n",
        "### 1.1 Con un audio (voz o música) no mayor a 30 segundos, utilizando la libreria Librosa (https://librosa.org/), numpy, pytorch, implementa operaciones fundamentales como:\n",
        "- Media\n",
        "- Kurtosis\n",
        "- Skewness\n",
        "- Zero Crossing Rate\n",
        "- Spectral Centroid\n",
        "- Energía\n",
        "- RMSE\n",
        "- Frecuencia fundamental\n",
        "<p align=\"justify\">\n",
        "Estas operaciones son fundamentales en el proceso de extracción de características. Explica el resultado obtenido y que significa cada uno."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa torchaudio"
      ],
      "metadata": {
        "id": "k7OVWDp4c_p_"
      },
      "id": "k7OVWDp4c_p_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d0ab6ee5-d7a3-4cf7-9aee-1d1a76b5525f",
      "metadata": {
        "tags": [],
        "id": "d0ab6ee5-d7a3-4cf7-9aee-1d1a76b5525f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#Subir archivo de audio en Colab\n",
        "print(\"Suba archivo de audio: \")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "Wg1Q1ckRc7za"
      },
      "id": "Wg1Q1ckRc7za",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ruta de archivo de audio\n",
        "ruta = \"Pedro.wav\"\n",
        "\n",
        "#Importación de archivo de audio\n",
        "audio, sr = librosa.load(ruta, sr = None)\n",
        "\n",
        "#Creación de vector tiempo\n",
        "t = np.linspace(0, len(audio)/sr, len(audio))"
      ],
      "metadata": {
        "id": "Jyz8RANfdwed"
      },
      "id": "Jyz8RANfdwed",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo de la media del audio\n",
        "media = np.mean(audio)\n",
        "print(\"Media:\", media)"
      ],
      "metadata": {
        "id": "67RhNEreBsnl"
      },
      "id": "67RhNEreBsnl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La media es el valor de la suma de todos los datos y se divide en el número total de datos."
      ],
      "metadata": {
        "id": "ERnYxecm7jui"
      },
      "id": "ERnYxecm7jui"
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo de la kurtosis del audio\n",
        "kurtosis = (np.mean((audio-media) **4) / np.sqrt(np.var(audio)) ** 4) - 3\n",
        "print(\"Kurtosis:\", kurtosis)"
      ],
      "metadata": {
        "id": "S1Uw0mkyBvBQ"
      },
      "id": "S1Uw0mkyBvBQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existen 3 tipos de kurtosis:\n",
        "* Leptocúrtica (kurtosis > 3)\n",
        "* Platicúrtica (kurtosis < 3)\n",
        "* Mesocúrtica (kurtosis = 3)\n",
        "\n",
        "Ya que nuestro reultado es menor a 3, significa que estamos frente a una kurtosis platicúrtica. Este tipo de distribuciones tienen menos valores atípicos, teniendo también una mayor estabilidad."
      ],
      "metadata": {
        "id": "WutvmTuvDC2a"
      },
      "id": "WutvmTuvDC2a"
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo de la skewness del audio\n",
        "skewness = (np.mean((audio-media) **3) / np.sqrt(np.var(audio)) ** 3)\n",
        "print(\"Skewness:\", skewness)"
      ],
      "metadata": {
        "id": "_Rmc9U4YB0H6"
      },
      "id": "_Rmc9U4YB0H6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La skewness es una medida de aimetría de una función. Existen 2 tipos:\n",
        "* Positivo: Indica que la distribución es asimétrica hacia la derecha.\n",
        "* Negativo Indica que la distribución es asimétrica hacia la izquierda.\n",
        "Cuando el resultado es 0, significa que hay simetría.\n",
        "\n",
        "Ya que nuestro resultado es positivo, significa que tenemos una distribución asimétrica hacia la derecha por lo que se pueden esperar pequeñas pérdidas recurrentes y pocas ganancias importantes."
      ],
      "metadata": {
        "id": "NhBYzqEGElNb"
      },
      "id": "NhBYzqEGElNb"
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo del zero crossing rate del audio\n",
        "zeroCrossingRate = librosa.feature.zero_crossing_rate(audio)\n",
        "print(\"Zero Crossing Rate:\", np.mean(zeroCrossingRate))"
      ],
      "metadata": {
        "id": "448HGW4IBz2d"
      },
      "id": "448HGW4IBz2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El zero crossing rate indica la cantidad de veces que una señal pasa por el 0, indicando que al ser mayor el resultado, mayor es el ruido en la señal.\n",
        "\n",
        "Ya que nuestro resultado es alrededor de 0.0544 significa que no hay mucho ruido presente en nuestra señal."
      ],
      "metadata": {
        "id": "ubelhVr1F4ND"
      },
      "id": "ubelhVr1F4ND"
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo del spectral centroid del audio\n",
        "spectralCentroid = librosa.feature.spectral_centroid(y = audio, sr=sr)\n",
        "print(\"Spectral Centroid:\", np.mean(spectralCentroid))"
      ],
      "metadata": {
        "id": "u8dIIzIFBzvi"
      },
      "id": "u8dIIzIFBzvi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El spectral centroid es el \"centro de gravedad\" del espectro de la señal.\n",
        "El tener un resultado alto significa que tiende a tener más energía en frecuencias más altas, y una señal con spectral centroid bajo tendrá más energía en frecuencias más bajas.\n",
        "\n",
        "Ya que nuestro resultado es alto se concluye que la señal tiene más energía en frecuencias altas."
      ],
      "metadata": {
        "id": "sL200-vWGg3f"
      },
      "id": "sL200-vWGg3f"
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo de la energía del audio\n",
        "energia = np.sum(audio**2) / len(audio)\n",
        "print(\"Energía:\", energia)"
      ],
      "metadata": {
        "id": "TMZb1d3QBzUb"
      },
      "id": "TMZb1d3QBzUb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La energía indica la cantidad total de potecia contenida en la señal durante un período de tiempo específico.\n",
        "\n",
        "Ya que nuestro resultado se puede considerar bajo, indica que la señal tiene baja potencia y es menos audible comparado con una señal con mayor energía."
      ],
      "metadata": {
        "id": "mRATejmwI4aE"
      },
      "id": "mRATejmwI4aE"
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo del rmse del audio\n",
        "rmse = librosa.feature.rms(y = audio)\n",
        "print(\"RMSE:\", np.mean(rmse))"
      ],
      "metadata": {
        "id": "D1936D79CAwt"
      },
      "id": "D1936D79CAwt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El rmse es una métrica usada para evaluar la precisión de un modelo de regresión. Entrega la diferencia entre los valores predichos por un modelo y los valores observados. Cuando el rmse tiene un valor de 0 significa que tiene un ajuste perfecto, por lo que mientras menor sea el valor, mejor será el modelo y sus predicciones.\n",
        "\n",
        "Ya que nuestro resultado se acerca al 0 podemos deducir que su modelo es bastante bueno así como sus predicciones."
      ],
      "metadata": {
        "id": "m47ZYzZ7K1ta"
      },
      "id": "m47ZYzZ7K1ta"
    },
    {
      "cell_type": "code",
      "source": [
        "#Frecuencia fundamental del audio\n",
        "f0 = librosa.pyin(audio, fmin = librosa.note_to_hz(\"C2\"), fmax = librosa.note_to_hz(\"C7\"))\n",
        "print(\"Frecuencia fundamental:\", np.nanmax(f0))"
      ],
      "metadata": {
        "id": "Xnv_LmQDCAp_"
      },
      "id": "Xnv_LmQDCAp_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La frecuencia fundamental es la frecuencia más baja de todas.\n",
        "\n"
      ],
      "metadata": {
        "id": "DYsWb55M68yK"
      },
      "id": "DYsWb55M68yK"
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfica de señal de audio original\n",
        "plt.figure(figsize = (20,5))\n",
        "plt.plot(t, audio)\n",
        "plt.xlabel(\"Tiempo(s)\")\n",
        "plt.ylabel(\"Amplitud\")"
      ],
      "metadata": {
        "id": "8uQKqkjtxxTo"
      },
      "id": "8uQKqkjtxxTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reproducción de audio\n",
        "Audio(audio, rate = sr)"
      ],
      "metadata": {
        "id": "4k0Zib5Ey6V7"
      },
      "id": "4k0Zib5Ey6V7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eb8294e2",
      "metadata": {
        "id": "eb8294e2"
      },
      "source": [
        "## 2. Implementaciones\n",
        "\n",
        "### 2.1 Utilizando Pytorch Audio obtenga el espectrograma del audio original\n",
        "El espectrograma debe producirse para valores número de muestras para la transformada rápida de fourier de  32, 128, 512.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf800d9",
      "metadata": {
        "id": "3cf800d9"
      },
      "outputs": [],
      "source": [
        "#Importar archivo de audio como tensor\n",
        "audioTensor, fs = torchaudio.load(ruta)\n",
        "\n",
        "#Números de muestras pedidos\n",
        "muestras = [32, 128, 512]\n",
        "\n",
        "#Crear figura\n",
        "plt.figure(figsize=(18, 4))\n",
        "\n",
        "for i, n in enumerate(muestras):\n",
        "\n",
        "    #Cálculo de espectrograma de Mel\n",
        "    spectrogram = torchaudio.transforms.MelSpectrogram(n_fft=n)(audioTensor)\n",
        "\n",
        "    #Espectrograma a decibelios\n",
        "    spectrogram = torchaudio.transforms.AmplitudeToDB()(spectrogram)\n",
        "\n",
        "    #Ver espectrograma\n",
        "    plt.subplot(1, len(muestras), i+1)\n",
        "    plt.imshow(spectrogram[0].numpy(), aspect=\"auto\", origin=\"lower\", interpolation = \"nearest\")\n",
        "    plt.xlabel(\"Tiempo(s)\")\n",
        "    plt.ylabel(\"Frecuencia(Hz)\")\n",
        "    plt.title(f\"Tamaño de fft = {n}\")\n",
        "    plt.colorbar(label=\"Amplitud(dB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido al falta de muestras se puede observar un tipo de fragmentación en el espectrograma."
      ],
      "metadata": {
        "id": "01SAh8zXnanw"
      },
      "id": "01SAh8zXnanw"
    },
    {
      "cell_type": "markdown",
      "id": "2c2d43d8",
      "metadata": {
        "id": "2c2d43d8"
      },
      "source": [
        "### 2.2 Utilizando Pytorch audio y Librosa, implementa Mel Frequency Cepstral Coefficients (MFCCs) (opcional)\n",
        "\n",
        "Sigue el siguiente ejemplo (https://www.kaggle.com/code/ilyamich/mfcc-implementation-and-tutorial) y explica que significa el resultado obtenido, graficando los coeficientes en un espectrograma. Investiga sobre Cepstral Analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c64b67c8",
      "metadata": {
        "id": "c64b67c8"
      },
      "source": [
        "### 3. Audio Processing\n",
        "### 3.1 En matlab, del paquete de procesamiento de audio, debes elegir una función de la librería, estudiarla y hacer un ejemplo.\n",
        "\n",
        "Debes enviar un informe en PDF de 1 (una) página explicando, el algoritmo seleccionado, como funciona y el ejemplo que desarrollaste. Incluye por lo menos un gráfico que demuestre el trabajo realizado.\n",
        "\n",
        "Debes subir a tu repositorio el código en matlab con dicha solución.\n",
        "\n",
        "En el sitio  https://la.mathworks.com/help/audio/index.html?s_tid=CRUX_lftnav y https://la.mathworks.com/help/audio/audio-processing-algorithm-design.html, encuentras diferentes funciones para generar efectos como reverberancia o control de la onda (compresores, gates, etc)\n",
        "\n",
        "Así mismo, en el sitio https://la.mathworks.com/help/signal/measurements-and-feature-extraction.html, encuentras ejemplos para extracción de caracteristicas de la señal de audio, por ejemplo métricas de pulso y de transición.\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0",
      "metadata": {
        "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0"
      },
      "source": [
        "## 5. Referencias\n",
        "<p align=\"justify\">\n",
        "    \n",
        "[Análisis espectral para audio] https://ccrma.stanford.edu/~jos/mdft/mdft-python.html\n",
        "\n",
        "[Análisis espectral] https://currents.soest.hawaii.edu/ocn_data_analysis/_static/Spectrum.html\n",
        "\n",
        "[MFCC]https://medium.com/@derutycsl/intuitive-understanding-of-mfccs-836d36a1f779\n",
        "\n",
        "[Cepstrum]https://www.kuniga.me/blog/2021/12/11/pitch-via-cepstrum.html\n",
        "\n",
        "[LPC] https://www.youtube.com/watch?v=DIr6SPdK4NA\n",
        "\n",
        "[LPC] https://www.kuniga.me/blog/2021/05/13/lpc-in-python.html\n",
        "\n",
        "[MFCC] https://librosa.org/doc/0.10.1/generated/librosa.feature.mfcc.html#librosa.feature.mfcc\n",
        "\n",
        "[MFCC] https://pytorch.org/audio/main/generated/torchaudio.transforms.MFCC.html\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}