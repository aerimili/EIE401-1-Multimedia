{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerimili/EIE401-1-Multimedia/blob/main/Actividades/Actividad_7/Actividad_7_VillalobosAlejandra_20914803-K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a",
      "metadata": {
        "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a"
      },
      "source": [
        "<h1><center>\n",
        "\n",
        "</center></h1>\n",
        "<font size=\"6\"><center>\n",
        "EIE 401\n",
        "PROCESAMIENTO DIGITAL MULTIMEDIA\n",
        "</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c",
      "metadata": {
        "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c"
      },
      "source": [
        "\n",
        "<center><h2>Actividad 7</h2></center>\n",
        "<center><h3>Image</h3></center>\n",
        "<center><h3>Profesor: Jorge Cardenas</h3></center>\n",
        "\n",
        "<center><h3>Por: Alejandra Villalobos</h3></center>\n",
        "<center><h5>Pontificia Universidad Catolica de Valparaiso</h5></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d",
      "metadata": {
        "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d"
      },
      "source": [
        "## 1. Operaciones usando Pytorch y OpenCV\n",
        "\n",
        "### 1.1 Instala Numpy, Pytorch y OpenCV:\n",
        "- Carga una imagen desde un archivo con extensi√≥n JPG, usando numpy, pytorch y opencv.\n",
        "- Presenta la imagen\n",
        "- Transforma la imagen de color a escala de grises usando cada uno de los paquetes\n",
        "- Guarda la imagen nueva.\n",
        "- Presenta la imagen transformada en el notebook.\n",
        "\n",
        "<p align=\"justify\">\n",
        "Asegurate de presentar adecuandamente la imagen, usando Matplotlib u otro medio de ploteo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "id": "d0ab6ee5-d7a3-4cf7-9aee-1d1a76b5525f",
      "metadata": {
        "tags": [],
        "id": "d0ab6ee5-d7a3-4cf7-9aee-1d1a76b5525f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#Subir archivo Tokio.jpg en Colab\n",
        "print(\"Suba Tokyo.jpg: \")\n",
        "uploadedjpg = files.upload()\n",
        "\n",
        "#Subir archivo image.png en Colab\n",
        "print(\"Suba image.png: \")\n",
        "uploadedpng = files.upload()"
      ],
      "metadata": {
        "id": "Wjhw5895eXsH",
        "collapsed": true
      },
      "id": "Wjhw5895eXsH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rutajpg = \"Tokyo.jpg\" #Ruta donde se encuentra imagen jpg"
      ],
      "metadata": {
        "id": "6XwyrFspiVlM"
      },
      "id": "6XwyrFspiVlM",
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Numpy"
      ],
      "metadata": {
        "id": "DrtEQ93IiWq1"
      },
      "id": "DrtEQ93IiWq1"
    },
    {
      "cell_type": "code",
      "source": [
        "imagenPil = Image.open(rutajpg) #Cargar imagen jpg original"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y6ZH_1qXiHh2"
      },
      "id": "y6ZH_1qXiHh2",
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen original\n",
        "plt.imshow(imagenPil)\n",
        "plt.title(\"Imagen jpg con Numpy\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "WDExEePGnwRj"
      },
      "id": "WDExEePGnwRj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenNpGris = imagenPil.convert(\"L\") #Transformar imagen a escala de grises"
      ],
      "metadata": {
        "id": "qHr2oWK4nxx-"
      },
      "id": "qHr2oWK4nxx-",
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guardarNumpy = imagenNpGris.save(\"imagenNpGris.jpg\") #Guardar imagen nueva\n",
        "\n",
        "imagenNpGrisSave = Image.open(\"imagenNpGris.jpg\") #Cargar imagen nueva"
      ],
      "metadata": {
        "id": "E3KudG5WpA-l"
      },
      "id": "E3KudG5WpA-l",
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen en escala de grises\n",
        "plt.imshow(imagenNpGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Numpy en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Aeo65AXlqMJ2"
      },
      "id": "Aeo65AXlqMJ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen jpg original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPil)\n",
        "plt.title(\"Imagen jpg con Numpy\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenNpGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Numpy en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "biiBiC3fqpZJ"
      },
      "id": "biiBiC3fqpZJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Torch"
      ],
      "metadata": {
        "id": "7EDKTEdrsE3d"
      },
      "id": "7EDKTEdrsE3d"
    },
    {
      "cell_type": "code",
      "source": [
        "imagenTorch = transforms.ToTensor()(imagenPil) #Tranformar imagen a tensor"
      ],
      "metadata": {
        "id": "WMrGGNbDtw1S"
      },
      "id": "WMrGGNbDtw1S",
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen original trabajada con Torch\n",
        "plt.imshow(imagenTorch.permute(1,2,0))\n",
        "plt.title(\"Imagen jpg con Torch\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "bI_Ord7fsH6z"
      },
      "id": "bI_Ord7fsH6z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenTorchGris = transforms.Grayscale()(imagenTorch) #Transformar imagen torch a escala de grises"
      ],
      "metadata": {
        "id": "l9yRNnCpuSBq"
      },
      "id": "l9yRNnCpuSBq",
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenTorchGrisPil = transforms.ToPILImage()(imagenTorchGris) #Tranformar tensor gris a imagen PIL\n",
        "\n",
        "guardarTorch = imagenTorchGrisPil.save(\"imagenTorchGris.jpg\") #Guardar imagen nueva\n",
        "\n",
        "imagenTorchGrisSave = Image.open(\"imagenTorchGris.jpg\") #Cargar imagen nueva"
      ],
      "metadata": {
        "id": "v9syTwrVu0jl"
      },
      "id": "v9syTwrVu0jl",
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen en escala de grises trabajada con Torch\n",
        "plt.imshow(imagenTorchGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Torch en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "lp8eCHOSvL5Z"
      },
      "id": "lp8eCHOSvL5Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen jpg original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenTorch.permute(1,2,0))\n",
        "plt.title(\"Imagen jpg con Torch\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenTorchGrisSave, cmap=\"gray\")\n",
        "plt.title(\"Imagen jpg con Torch en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "-s6zwraewlSg"
      },
      "id": "-s6zwraewlSg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####OPENCV"
      ],
      "metadata": {
        "id": "VIlyonK-iCTC"
      },
      "id": "VIlyonK-iCTC"
    },
    {
      "cell_type": "code",
      "source": [
        "imagenCv = cv2.imread(rutajpg) #Cargar imagen original con OpenCv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wKlMpjSqfeva"
      },
      "id": "wKlMpjSqfeva",
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen original trabajada con OpenCv\n",
        "plt.imshow(imagenCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B758iVMUxCso"
      },
      "id": "B758iVMUxCso",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenAGriscv = cv2.cvtColor(imagenCv, cv2.COLOR_BGR2GRAY) #Transformar imagen a escala de grises\n",
        "\n",
        "guardarImagen = cv2.imwrite(\"Tokyogriscv.jpg\", imagenAGriscv) #Guardar imagen nueva\n",
        "\n",
        "imagenGrisCv = cv2.imread(\"Tokyogriscv.jpg\") #Cargar imagen en escala de grises con OpenCv"
      ],
      "metadata": {
        "id": "cc6Eflm8xAcX"
      },
      "id": "cc6Eflm8xAcX",
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen en escala de grises trabajada con OpenCv\n",
        "plt.imshow(imagenGrisCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7TRgjL7uzwJp"
      },
      "id": "7TRgjL7uzwJp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen jpg original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenGrisCv[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen jpg con OpenCv en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "EOzwZ8VtqFbk"
      },
      "id": "EOzwZ8VtqFbk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28db8b8d",
      "metadata": {
        "id": "28db8b8d"
      },
      "source": [
        "## 2. Multiples operaciones con tensores\n",
        "### ¬°USA LA IMAGEN ADJUNTA image.png!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rutapng = \"image.png\" #Ruta donde se encuentra imagen png\n",
        "imagenPng = cv2.imread(rutapng) #Cargar imagen png original\n",
        "imagenGrisPng = cv2.cvtColor(imagenPng, cv2.COLOR_BGR2GRAY) #Transformar imagen png a escala de grises"
      ],
      "metadata": {
        "id": "Gr885TdatjRr"
      },
      "id": "Gr885TdatjRr",
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y en escala de grises\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenGrisPng, cmap = \"gray\")\n",
        "plt.title(\"Imagen png en escala de grises\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xjSEF0Q90sFD"
      },
      "id": "xjSEF0Q90sFD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b0f7428a",
      "metadata": {
        "id": "b0f7428a"
      },
      "source": [
        "#### 2.1 Aplica una transformaci√≥n puntual. Modifica el valor de los pixeles considerando un valor de umbral (threshold). la funci√≥n de treshold debe ser una rampa con una pendiente dada (tu defines el valor de la pendiente) y cuyo valor m√≠nimo ser√° 0 y el m√°ximo ser√° 255 (valores t√≠picos de los pixeles)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 128 #Valor de umbral\n",
        "slope = 2 #Valor de pendiente\n",
        "\n",
        "def thre(pixel, thres, slope):\n",
        "  \"\"\"\n",
        "  Calcula la transformaci√≥n puntual de una imagen.\n",
        "\n",
        "  Par√°metros:\n",
        "\n",
        "  pixel: Pixel de la imagen a transformar.\n",
        "  thres: Umbral.\n",
        "  slope: Pendiente.\n",
        "  \"\"\"\n",
        "  #Si el pixel es menor al umbral, aplica la transformaci√≥n con la pendiente\n",
        "  if pixel<thres:\n",
        "    return max(0,pixel*slope)\n",
        "  #Si el pixel es mayor o igual al umbral, aplica la transformaci√≥n con la pendiente\n",
        "  else:\n",
        "    return min(255,pixel*slope)\n",
        "\n",
        "imgTransf = np.zeros_like(imagenPng) #Nos aseguramos que el valor minimo sea 0 y el m√°ximo 255\n",
        "\n",
        "#Iteraci√≥n sobre cada pixel de la imagen\n",
        "for i in range(imagenPng.shape[0]):\n",
        "  for j in range(imagenPng.shape[1]):\n",
        "    for c in range(imagenPng.shape[2]):\n",
        "      imgTransf[i,j,c] = thre(imagenPng[i,j,c], threshold, slope) #Aplica la transformaci√≥n a cada canal."
      ],
      "metadata": {
        "id": "KDvA43azeKPF"
      },
      "id": "KDvA43azeKPF",
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y con transformaci√≥n puntual\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgTransf[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png con transformaci√≥n puntual\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5inGthHxgaGc"
      },
      "id": "5inGthHxgaGc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede apreciar que la transformaci√≥n cambia la intensidad dependiendo si los pixeles est√°n por debajo o encima del umbral."
      ],
      "metadata": {
        "id": "Dh68fZH4tGt3"
      },
      "id": "Dh68fZH4tGt3"
    },
    {
      "cell_type": "markdown",
      "id": "c203b1f0",
      "metadata": {
        "id": "c203b1f0"
      },
      "source": [
        "#### 2.2 Aplica una transformaci√≥n en la vecindad.\n",
        "- Debes hacer una vecindad con dimensiones de 5x5 pixeles.\n",
        "- Aplica la transformaci√≥n de tal forma que los pixeles cambien para tener el valor correspondiente al m√°ximo de todos los vecinos.\n",
        "- Debes hacer la misma operaci√≥n a lo largo y ancho de toda la imagen. Esto implica, de forma iterativa, recorrer la imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vecindad(imagen, Tvecindad):\n",
        "  \"\"\"\n",
        "  Calcula la transformaci√≥n en la vecindad de una imagen.\n",
        "\n",
        "  Par√°metros:\n",
        "\n",
        "  imagen: Imagen a transformar.\n",
        "  Tvecindad: Tama√±o de la vecindad.\n",
        "  \"\"\"\n",
        "  imgVec = np.zeros_like(imagen) #Nos aseguramos que el valor minimo sea 0 y el m√°ximo 255\n",
        "\n",
        "  #Iteraci√≥n sobre la imagen con desplazamiento de tama√±o de vecindad\n",
        "  for i in range(imagen.shape[0] - Tvecindad + 1):\n",
        "    for j in range(imagen.shape[1] - Tvecindad + 1):\n",
        "\n",
        "      vecindad = imagen[i:i+Tvecindad, j:j+Tvecindad] #vecindad de imagen en posici√≥n actual\n",
        "      maxVec = np.max(vecindad, axis=(0,1)) #Valor m√°ximo de la vecindad\n",
        "      imgVec[i:i+Tvecindad, j:j+Tvecindad] = maxVec #Se asigna el valor m√°ximo a toda la vecindad\n",
        "\n",
        "  return imgVec\n",
        "\n",
        "Tvecindad = 5 #Tama√±o de la vecindad de 5x5\n",
        "imagenVecindad = vecindad(imagenPng, Tvecindad) #Se crea imagen con transformaci√≥n en la vecindad"
      ],
      "metadata": {
        "id": "KT034PdiEBG-"
      },
      "id": "KT034PdiEBG-",
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y con transformaci√≥n en la vecindad\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenVecindad[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png con transformaci√≥n en la vecindad\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Gao-UOAxGMC9"
      },
      "id": "Gao-UOAxGMC9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La transformaci√≥n en la vecindad afecta a cada pixel, reemplazandolo por una vecindad cuadrada de tama√±o elegido, esto provoca un efecto de \"imagen pixeleada\", perdiendo resoluci√≥n."
      ],
      "metadata": {
        "id": "iXFEHQobu8kA"
      },
      "id": "iXFEHQobu8kA"
    },
    {
      "cell_type": "markdown",
      "id": "5bf09ac2",
      "metadata": {
        "id": "5bf09ac2"
      },
      "source": [
        "#### 2.3 Aplica transformaci√≥n de intensidad\n",
        "- Debes hacer una vecindad con dimensiones de 10x10 pixeles.\n",
        "- Aplica la transformaci√≥n que aparece en la ecuaci√≥n de tal forma que los pixeles cambien dependiendo de la posici√≥n (r) y el coeficiente c (de tu elecci√≥n).\n",
        "- Debes hacer la misma operaci√≥n a lo largo y ancho de toda la imagen. ESto implica, de forma iterativa, recorrer la imagen."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tvecindad2 = 10 #Tama√±o de vecindad de 10x10\n",
        "c = 20 #Valor coeficiente c\n",
        "\n",
        "def intensidad(c, r):\n",
        "  \"\"\"\n",
        "  Calcula la transformaci√≥n de intensidad.\n",
        "\n",
        "  Par√°metros:\n",
        "\n",
        "  c: Coeficiente \"c\".\n",
        "  r: Posici√≥n.\n",
        "  \"\"\"\n",
        "  return c*np.log(1+r)\n",
        "\n",
        "def transIntensidad(imagen, Tvecindad, c):\n",
        "  \"\"\"\n",
        "  Calcula la transformaci√≥n de intensidad en la vecindad de una imagen.\n",
        "\n",
        "  Par√°metros:\n",
        "\n",
        "  imagen: Imagen a transformar\n",
        "  Tvecindad: Tama√±o de la vecindad.\n",
        "  c: Coeficiente \"c\"\n",
        "  \"\"\"\n",
        "  imgVec = np.zeros_like(imagen) #Nos aseguramos que el valor minimo sea 0 y el m√°ximo 255\n",
        "\n",
        "  #Iteraci√≥n sobre la imagen con desplazamiento de tama√±o de vecindad\n",
        "  for i in range(imagen.shape[0] - Tvecindad + 1):\n",
        "    for j in range(imagen.shape[1] - Tvecindad + 1):\n",
        "      vecindad = imagen[i:i+Tvecindad, j:j+Tvecindad] #Vecindad de imagen en posici√≥n actual\n",
        "\n",
        "      transVec = intensidad(c,vecindad) #Transformaci√≥n de intensidad en la vecindad\n",
        "      transVec = np.clip(transVec, 0, 255) #Nos aseguramos que el valor minimo sea 0 y el m√°ximo 255\n",
        "      imgVec[i:i+Tvecindad, j:j+Tvecindad] = transVec #Asignamos transformaci√≥n de intensidad a vecindad\n",
        "\n",
        "  return imgVec\n",
        "\n",
        "imagenVecindad2 = transIntensidad(imagenPng, Tvecindad2, c) #Se crea imagen con transformaci√≥n de intensidad"
      ],
      "metadata": {
        "id": "jhW6KGetjpfD"
      },
      "id": "jhW6KGetjpfD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen png original y con transformaci√≥n de intensidad\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagenPng[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imagenVecindad2[:,:,[2,1,0]])\n",
        "plt.title(\"Imagen png con transformaci√≥n de intensidad\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YPnhO2Z3KpZa"
      },
      "id": "YPnhO2Z3KpZa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la figura que se obtiene, se puede ver que se modifica la intensidad de los pixeles de la imagen, cambiando el brillo y contraste de la imagen final."
      ],
      "metadata": {
        "id": "y0eeeLT8x_UI"
      },
      "id": "y0eeeLT8x_UI"
    },
    {
      "cell_type": "markdown",
      "id": "d9230405",
      "metadata": {
        "id": "d9230405"
      },
      "source": [
        "#### 2.4 Operaci√≥n con Kernel\n",
        "- Realiza tres operaciones de convoluci√≥n en cascada.\n",
        "- Utiliza torch nn.Conv2d\n",
        "- Debes calcular el stride, padding y dem√°s par√°metros para que obtengas 16 canales de salida.\n",
        "- Muestra una imagen de cada canal resultante de la convoluci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "id": "f8bb041e",
      "metadata": {
        "id": "f8bb041e"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagenPngTorch = transforms.ToTensor()(imagenPng) #Tranformar imagen a tensor\n",
        "imagenPngTorch = imagenPngTorch.unsqueeze(0) #Agregar canal de batch"
      ],
      "metadata": {
        "id": "ywyMViTwSKwG"
      },
      "id": "ywyMViTwSKwG",
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = 3 #Valor de kernel\n",
        "stride = 1 #Valor de stride\n",
        "padding = 1 #Valor de padding\n",
        "\n",
        "conv1 = nn.Conv2d(3, 8, kernel, stride, padding) #1era capa de convoluci√≥n, entran 3 canales y salen 8.\n",
        "conv2 = nn.Conv2d(8, 8, kernel, stride, padding) #2da capa de convoluci√≥n, entran 8 canales y salen 8.\n",
        "conv3 = nn.Conv2d(8, 16, kernel, stride, padding) #3era capa de convoluci√≥n, entran 8 canales y salen 16.\n",
        "\n",
        "#Convoluci√≥n en cascada\n",
        "im1 = conv1(imagenPngTorch)\n",
        "im2 = conv2(im1)\n",
        "im3 = conv3(im2)"
      ],
      "metadata": {
        "id": "1xckCUXtQqNm"
      },
      "id": "1xckCUXtQqNm",
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar cada canal\n",
        "fig, axes = plt.subplots(4,4,figsize=(12, 12))\n",
        "for i in range(16):\n",
        "  fila = i//4\n",
        "  columna = i%4\n",
        "  axes[fila, columna].imshow(im3[0, i].detach().numpy(), cmap=\"gray\")\n",
        "  axes[fila, columna].set_title(f\"Canal {i+1}\")\n",
        "  axes[fila, columna].axis(\"off\")"
      ],
      "metadata": {
        "id": "fCP2D38SzYn3"
      },
      "id": "fCP2D38SzYn3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede ver que, seg√∫n las im√°genes resultantes, cada canal \"resalta\" partes diferentes de la imagen"
      ],
      "metadata": {
        "id": "BYY2fL_JzhC-"
      },
      "id": "BYY2fL_JzhC-"
    },
    {
      "cell_type": "markdown",
      "id": "eb8294e2",
      "metadata": {
        "id": "eb8294e2"
      },
      "source": [
        "## 3. Realiza la inversi√≥n de imagen\n",
        "\n",
        "### 3.1 Utilizando estrictamente numpy, busca y usa una imagen binaria y realizar la inversi√≥n de dicha imagen.\n",
        "### Recuerda adjuntar la imagen a la entrega de tu trabajo.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#Subir imagen binaria en Colab\n",
        "print(\"Suba archivo binaria.png: \")\n",
        "uploaded3 = files.upload()"
      ],
      "metadata": {
        "id": "FpyJTKK_zYuE"
      },
      "id": "FpyJTKK_zYuE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "3cf800d9",
      "metadata": {
        "id": "3cf800d9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "ruta3 = \"binaria.png\" #Ruta donde se encuentra imagen binaria\n",
        "\n",
        "imagen3 = Image.open(ruta3) #Cargar imagen binaria\n",
        "imagen3Np = np.array(imagen3) #Convertir imagen a un array de numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M = imagen3Np.shape[0] #Primer canal de la imagen\n",
        "N = imagen3Np.shape[1] #Segundo canal de la imagen\n",
        "\n",
        "imgInvertidaNp = np.zeros_like(imagen3Np) #Nos aseguramos que el valor minimo sea 0 y el m√°ximo 255\n",
        "\n",
        "#Inversi√≥n de la imagen\n",
        "for i in range(M):\n",
        "  for j in range(N):\n",
        "      #Si un pixel de la imagen es 255 se cambia a 0\n",
        "      if imagen3Np[i, j] == 255:\n",
        "        imgInvertidaNp[i, j] = 0\n",
        "      #Si un pixel de la imagen es 0 se cambia a 255\n",
        "      else:\n",
        "        imgInvertidaNp[i, j] = 255"
      ],
      "metadata": {
        "id": "PaQZ4gTqlhNl"
      },
      "id": "PaQZ4gTqlhNl",
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen binaria original e invertida con numpy\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagen3Np, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria original con Numpy\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgInvertidaNp, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria invertida con Numpy\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "P3o5AtCFAjBB"
      },
      "id": "P3o5AtCFAjBB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2c2d43d8",
      "metadata": {
        "id": "2c2d43d8"
      },
      "source": [
        "### 3.1 Usando Pytorch y opencv, realiza la inversi√≥n de la misma imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Torch"
      ],
      "metadata": {
        "id": "UTteuWfB58TM"
      },
      "id": "UTteuWfB58TM"
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "id": "fdf35251",
      "metadata": {
        "id": "fdf35251"
      },
      "outputs": [],
      "source": [
        "imagen3Torch = transforms.ToTensor()(imagen3).squeeze() #Convertir imagen a tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M = imagen3Torch.shape[0] #Primer canal de la imagen\n",
        "N = imagen3Torch.shape[1] #Segundo canal de la imagen\n",
        "\n",
        "imgInvertidaTorch = torch.where(imagen3Torch == 1, torch.tensor(0), torch.tensor(1)) #Inversi√≥n de imagen"
      ],
      "metadata": {
        "id": "IrmcDtM0B8Kl"
      },
      "id": "IrmcDtM0B8Kl",
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen binaria riginal e invertida con Torch\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagen3Torch, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria original con Torch\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgInvertidaTorch, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria invertida con Torch\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "59Hh4JKqA_Gd"
      },
      "id": "59Hh4JKqA_Gd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####OpenCv"
      ],
      "metadata": {
        "id": "DUIJpZli5_Fo"
      },
      "id": "DUIJpZli5_Fo"
    },
    {
      "cell_type": "code",
      "source": [
        "imagen3Cv = cv2.imread(ruta3) #Cargar imagen binaria con OpenCv\n",
        "\n",
        "imgInvertidaCv = cv2.bitwise_not(imagen3Cv) #Inversi√≥n de imagen con OpenCv"
      ],
      "metadata": {
        "id": "Ne5o2q806Bd4"
      },
      "id": "Ne5o2q806Bd4",
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar imagen binaria original e invertida con OpenCv\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imagen3Cv, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria original con OpenCv\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgInvertidaCv, cmap=\"gray\")\n",
        "plt.title(\"Imagen binaria invertida con OpenCv\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Coiql6xD6aNe"
      },
      "id": "Coiql6xD6aNe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c64b67c8",
      "metadata": {
        "id": "c64b67c8"
      },
      "source": [
        "## 4. Segmentaci√≥n de imagen\n",
        "#### 4.1 Realiza un algoritmo para dividir una imagen con 3 canales RGB de 512x512, en parches (secciones) de 16x16. Presenta cada parche generado de la imagen.\n",
        "El algoritmo debe tolerar el cambio de imagen por una de menor tamano (128, 64). Claramente, en cada caso el n√∫mero de parches ser√° menor.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eceb0add",
      "metadata": {
        "id": "eceb0add",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def parches(imagen, Tparche):\n",
        "  \"\"\"\n",
        "  Divide una imagen en secciones (parches) y muestra cada secci√≥n.\n",
        "\n",
        "  Par√°metros:\n",
        "\n",
        "  imagen: Imagen a dividir.\n",
        "  Tparche: Tama√±o de la secci√≥n.\n",
        "  \"\"\"\n",
        "  parches = [] #Definir lista vac√≠a para almacenar los parches\n",
        "\n",
        "  #Iteraci√≥n sobre √±a imagen con un paso de tama√±o del parche\n",
        "  for i in range(0, imagen.shape[0], Tparche):\n",
        "    for j in range(0, imagen.shape[1], Tparche):\n",
        "      parche = imagen[i:i + Tparche, j:j + Tparche] #Extraer parche de Tparche x Tparche\n",
        "      parches.append(parche)\n",
        "\n",
        "  #Columnas y filas para mostrar los parches\n",
        "  nColumnas = int(np.ceil(np.sqrt(len(parches))))\n",
        "  nFilas = int(np.ceil(len(parches) / nColumnas))\n",
        "\n",
        "  fig, axes = plt.subplots(nFilas, nColumnas, figsize = (nColumnas, nFilas))\n",
        "\n",
        "  #Mostrar todos los parches\n",
        "  for i, parche in enumerate(parches):\n",
        "    ax = axes.flatten()[i]\n",
        "    ax.imshow(cv2.cvtColor(parche, cv2.COLOR_BGR2RGB))\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "  for ax in axes.flatten()[len(parches):]:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "\n",
        "Tparche = 16 #Tama√±o de parches de 16x16\n",
        "\n",
        "parches = parches(imagenPng, Tparche) #Divisi√≥n de imagen en secciones"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0",
      "metadata": {
        "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0"
      },
      "source": [
        "## 5. Referencias\n",
        "<p align=\"justify\">\n",
        "    \n",
        "[OpenCV] https://docs.opencv.org/4.x/d7/da8/tutorial_table_of_content_imgproc.html\n",
        "\n",
        "[inversion] https://medium.com/analytics-vidhya/inverting-an-image-using-numpys-broadcasting-method-1f5beb7f9fa5#:~:text=In%20order%20to%20invert%20the,negation)%20operation%20to%20the%20image.\n",
        "\n",
        "[Image.open] https://www.geeksforgeeks.org/python-pil-image-open-method/\n",
        "\n",
        "[Image module] https://pillow.readthedocs.io/en/stable/reference/Image.html\n",
        "\n",
        "[Conversi√≥n a escala de grises]https://www.delftstack.com/es/howto/python/convert-image-to-grayscale-python/\n",
        "\n",
        "[torchvision.transforms] https://pytorch.org/vision/0.9/transforms.html\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}